{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import KFold\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "movies = pd.read_csv('data/tmdb_6000_movies.csv')\n",
    "credits = pd.read_csv('data/tmdb_6000_credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on 'id'\n",
    "movies = movies.merge(credits,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for movie analysis\n",
    "movies = movies[['id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew', 'original_language']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing and duplicate values\n",
    "movies.dropna(inplace=True)\n",
    "movies.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely convert stringified JSON to a list of names\n",
    "def convert_safe(text):\n",
    "    \"\"\"Convert stringified JSON to a list of names.\"\"\"\n",
    "    try:\n",
    "        return [i['name'] for i in ast.literal_eval(text)]\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply conversion to 'genres' and 'keywords'\n",
    "movies['genres'] = movies['genres'].apply(convert_safe)\n",
    "movies['keywords'] = movies['keywords'].apply(convert_safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the top 3 cast members\n",
    "def convert_cast(text):\n",
    "    \"\"\"Keep only the top 3 cast members.\"\"\"\n",
    "    try:\n",
    "        return [i['name'] for i in ast.literal_eval(text)[:3]]\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast'] = movies['cast'].apply(convert_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch the director's name\n",
    "def fetch_director(text):\n",
    "    \"\"\"Fetch the director's name from the crew data.\"\"\"\n",
    "    try:\n",
    "        for i in ast.literal_eval(text):\n",
    "            if i['job'] == 'Director':\n",
    "                return [i['name']]\n",
    "        return []\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['crew'] = movies['crew'].apply(fetch_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the overview text into individual words\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split() if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove spaces in names for better matching\n",
    "def remove_space(L):\n",
    "    \"\"\"Remove spaces in names for better matching.\"\"\"\n",
    "    return [i.replace(\" \", \"\") for i in L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast'] = movies['cast'].apply(remove_space)\n",
    "movies['crew'] = movies['crew'].apply(remove_space)\n",
    "movies['genres'] = movies['genres'].apply(remove_space)\n",
    "movies['keywords'] = movies['keywords'].apply(remove_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all textual data into 'tags'\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the necessary columns\n",
    "new_movies = movies[['id', 'title', 'tags']]\n",
    "new_movies.dropna(subset=['tags'], inplace=True)\n",
    "new_movies.drop_duplicates(subset=['tags'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of tags to a single string and lowercase them\n",
    "new_movies['tags'] = new_movies['tags'].apply(lambda x: \" \".join(x)).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PorterStemmer for stemming words\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Function to apply stemming to text\n",
    "def stems(text):\n",
    "    \"\"\"Apply stemming to text.\"\"\"\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_movies['tags'] = new_movies['tags'].apply(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorization to convert tags into numerical data\n",
    "tfidf = TfidfVectorizer(max_features=6000, stop_words='english')\n",
    "vector = tfidf.fit_transform(new_movies['tags']).toarray()\n",
    "\n",
    "# Save the TF-IDF model and vectorized data\n",
    "pickle.dump(tfidf, open('processed_data/tfidf_vectorizer.pkl', 'wb'))\n",
    "pickle.dump(vector, open('processed_data/vectorized_data.pkl', 'wb'))\n",
    "\n",
    "# Train a KNN model on the vectorized data\n",
    "knn = NearestNeighbors(n_neighbors=10, metric='cosine', algorithm='brute')\n",
    "knn.fit(vector)\n",
    "\n",
    "# Save the trained KNN model\n",
    "pickle.dump(knn, open('processed_data/optimized_knn.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity matrix for visualization\n",
    "similarity = cosine_similarity(vector)\n",
    "pickle.dump(similarity, open('processed_data/similarity.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained KNN model for recommendations\n",
    "optimized_knn = pickle.load(open('processed_data/optimized_knn.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend movies using KNN\n",
    "def recommend_knn(movie, k=5):\n",
    "    \"\"\"\n",
    "    Recommends movies similar to the selected movie using KNN.\n",
    "\n",
    "    Args:\n",
    "        movie (str): The title of the selected movie.\n",
    "        k (int): Number of recommendations to provide.\n",
    "\n",
    "    Returns:\n",
    "        list: List of recommended movie titles sorted by similarity.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the index of the input movie\n",
    "        index = new_movies[new_movies['title'] == movie].index[0]\n",
    "    except IndexError:\n",
    "        return [\"Movie not found in dataset.\"]\n",
    "\n",
    "    # Get recommendations using the pre-trained KNN model\n",
    "    distances, indices = optimized_knn.kneighbors([vector[index]], n_neighbors=k + 1)\n",
    "\n",
    "    # Pair titles with their distances\n",
    "    recommendations_with_distances = [\n",
    "        (new_movies.iloc[i].title, distances[0][j])\n",
    "        for j, i in enumerate(indices[0][1:])\n",
    "    ]\n",
    "\n",
    "    # Sort recommendations by similarity (lower distance means higher similarity)\n",
    "    sorted_recommendations = sorted(recommendations_with_distances, key=lambda x: x[1])\n",
    "\n",
    "    # Extract only the titles\n",
    "    recommendations = [title for title, _ in sorted_recommendations[:k]]\n",
    "    \n",
    "    # Remove duplicates from recommendations\n",
    "    recommendations = list(dict.fromkeys(recommendations))\n",
    "    \n",
    "    return recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate recommendation performance\n",
    "def evaluate_recommendation_performance(true_items, recommended_items):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of recommendations using Precision and Recall.\n",
    "\n",
    "    Args:\n",
    "    true_items (list): Ground truth indices or movie titles.\n",
    "    recommended_items (list): Predicted indices or movie titles.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing Precision and Recall scores.\n",
    "    \"\"\"\n",
    "    relevant_set = set(true_items)\n",
    "    recommended_set = set(recommended_items)\n",
    "    \n",
    "    true_positives = relevant_set.intersection(recommended_set)\n",
    "    \n",
    "    precision = len(true_positives) / len(recommended_set) if recommended_set else 0\n",
    "    recall = len(true_positives) / len(relevant_set) if relevant_set else 0\n",
    "    \n",
    "    return {\"Precision\": precision, \"Recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize similarity scores as a bar chart\n",
    "def visualize_similarity_scores_dynamic(selected_movie, k=5):\n",
    "    \"\"\"\n",
    "    Dynamically visualize similarity scores for recommended movies as a bar chart.\n",
    "\n",
    "    Args:\n",
    "    selected_movie (str): The movie selected by the user.\n",
    "    k (int): Number of recommendations to display.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the index of the selected movie\n",
    "        index = new_movies[new_movies['title'] == selected_movie].index[0]\n",
    "        \n",
    "        # Get recommendations using the pre-trained KNN model\n",
    "        distances, indices = optimized_knn.kneighbors([vector[index]], n_neighbors=k + 1)\n",
    "        recommended_indices = indices[0][1:]  # Exclude the first (input movie itself)\n",
    "        similarity_scores = [1 - distances[0][i] for i in range(1, len(distances[0]))]  # Convert distance to similarity\n",
    "        \n",
    "        # Map indices to movie titles\n",
    "        recommended_titles = [new_movies.iloc[i].title for i in recommended_indices]\n",
    "\n",
    "        # Visualize the similarity scores\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(recommended_titles, similarity_scores, color='skyblue')\n",
    "        plt.xlabel(\"Recommended Movies\")\n",
    "        plt.ylabel(\"Similarity Score\")\n",
    "        plt.title(f\"Similarity Scores for Recommendations of '{selected_movie}'\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    except IndexError:\n",
    "        print(f\"Error: Movie '{selected_movie}' not found in the dataset.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_recommended_movies_heatmap(selected_movie, similarity_matrix, movie_titles, k=10):\n",
    "    \"\"\"\n",
    "    Visualize a heatmap showing the similarity scores between the recommended movies.\n",
    "\n",
    "    Args:\n",
    "    selected_movie (str): The movie selected by the user.\n",
    "    similarity_matrix (numpy.ndarray): Cosine similarity matrix for the movies.\n",
    "    movie_titles (list): List of movie titles corresponding to the rows/columns of the matrix.\n",
    "    k (int): Number of recommendations to consider.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the index of the selected movie\n",
    "        index = movie_titles.index(selected_movie)\n",
    "\n",
    "        # Get indices of the top k similar movies\n",
    "        similarity_scores = list(enumerate(similarity_matrix[index]))\n",
    "        sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        top_k_indices = [idx for idx, score in sorted_scores[1:k+1]]\n",
    "\n",
    "        # Subset similarity matrix for the top k movies\n",
    "        subset_matrix = similarity_matrix[top_k_indices][:, top_k_indices]\n",
    "        subset_titles = [movie_titles[i] for i in top_k_indices]\n",
    "\n",
    "        # Plot heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            subset_matrix,\n",
    "            xticklabels=subset_titles,\n",
    "            yticklabels=subset_titles,\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            cbar=True\n",
    "        )\n",
    "        plt.title(f\"Cosine Similarity Heatmap for Top {k} Recommendations of '{selected_movie}'\")\n",
    "        plt.xlabel(\"Movies\")\n",
    "        plt.ylabel(\"Movies\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except ValueError:\n",
    "        print(f\"Error: Movie '{selected_movie}' not found in the dataset.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_knn_parallel(vector, k_values=[5, 10, 15], metric_values=['cosine', 'euclidean'], n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define a function to evaluate KNN performance for specific parameters\n",
    "    def evaluate_knn(k, metric):\n",
    "        scores = []\n",
    "        for train_index, test_index in kf.split(vector):\n",
    "            # Train KNN on the training data\n",
    "            knn = NearestNeighbors(n_neighbors=k, metric=metric, algorithm='brute')\n",
    "            knn.fit(vector[train_index])\n",
    "\n",
    "            # Compute distances for the test data\n",
    "            distances, indices = knn.kneighbors(vector[test_index])\n",
    "            avg_distance = np.mean(distances)\n",
    "            scores.append(avg_distance)\n",
    "        return {'k': k, 'metric': metric, 'score': np.mean(scores)}\n",
    "\n",
    "    # Use parallel processing to evaluate multiple configurations\n",
    "    results = Parallel(n_jobs=-1)(delayed(evaluate_knn)(k, metric) for k in k_values for metric in metric_values)\n",
    "    return sorted(results, key=lambda x: x['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn_model(movie_name, k):\n",
    "    \"\"\"\n",
    "    Evaluate the optimized KNN model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"\\nEvaluating model performance with optimized KNN...\")\n",
    "        # Find the index of the input movie\n",
    "        index = new_movies[new_movies['title'] == movie_name].index[0]\n",
    "\n",
    "        # Get predictions from the optimized KNN model\n",
    "        distances, indices = optimized_knn.kneighbors([vector[index]], n_neighbors=k + 1)\n",
    "        predicted_indices = indices[0][1:]  # Exclude the first (input movie itself)\n",
    "\n",
    "        # Generate ground truth\n",
    "        similarity_scores = list(enumerate(similarity[index]))\n",
    "        sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        true_indices = [i for i, score in sorted_scores if score >= 0.3 and i != index][:5]\n",
    "\n",
    "        # Convert indices to movie titles\n",
    "        predicted_titles = [new_movies.iloc[i].title for i in predicted_indices]\n",
    "        true_titles = [new_movies.iloc[i].title for i in true_indices]\n",
    "\n",
    "        # Load favorites and update true titles\n",
    "        favorites = pickle.load(open('processed_data/favorite.pkl', 'rb')) if os.path.exists('processed_data/favorite.pkl') else {}\n",
    "        if movie_name in favorites:\n",
    "            for favorite in favorites[movie_name]:\n",
    "                if favorite not in true_titles:\n",
    "                    true_titles.append(favorite)\n",
    "\n",
    "        # Evaluate recommendation metrics\n",
    "        metrics = evaluate_recommendation_performance(true_titles, predicted_titles)\n",
    "\n",
    "        # Display evaluation results\n",
    "        print(\"\\nOptimized KNN Performance Metrics:\")\n",
    "        print(f\"Precision: {metrics['Precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['Recall']:.4f}\")\n",
    "        print(\"\\nTrue Titles:\", true_titles)\n",
    "        print(\"Predicted Titles:\", predicted_titles)\n",
    "\n",
    "    except IndexError:\n",
    "        print(\"Error: Movie not found in the dataset.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save movie data for future use\n",
    "pickle.dump(new_movies, open('processed_data/movie_list.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation to find the best parameters for KNN\n",
    "print(\"\\nPerforming cross-validation...\")\n",
    "cv_results = cross_validate_knn_parallel(vector)\n",
    "best_params = cv_results[0] # Extract the best parameters\n",
    "print(f\"Best Parameters from Cross-validation: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the optimized KNN model using the best parameters\n",
    "best_k = best_params['k'] # Optimal number of neighbors\n",
    "best_metric = best_params['metric'] # Optimal distance metric\n",
    "\n",
    "# Initialize and train the optimized KNN model\n",
    "optimized_knn = NearestNeighbors(n_neighbors=best_k, metric=best_metric, algorithm='brute')\n",
    "optimized_knn.fit(vector)\n",
    "\n",
    "# Save the optimized KNN model to a file for later use\n",
    "pickle.dump(optimized_knn, open('processed_data/optimized_knn.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example movie for evaluation and visualization\n",
    "movie_name = \"Batman\"\n",
    "\n",
    "# Generate recommendations for the specified movie\n",
    "recommendations = recommend_knn(movie_name, k=best_k)\n",
    "print(f\"\\nRecommendations for '{movie_name}':\\n\")\n",
    "for rec in recommendations:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity scores dynamically as a bar chart\n",
    "visualize_similarity_scores_dynamic(movie_name, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie titles and similarity matrix for heatmap visualization\n",
    "movie_titles = new_movies['title'].tolist()\n",
    "similarity_matrix = pickle.load(open('processed_data/similarity.pkl', 'rb'))  \n",
    "\n",
    "# Visualize the similarity heatmap for the top recommendations\n",
    "visualize_recommended_movies_heatmap(movie_name, similarity_matrix, movie_titles, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the KNN model performance on the selected movie\n",
    "evaluate_knn_model(movie_name, k=best_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
